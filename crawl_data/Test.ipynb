{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkeeFZH2W8JMy9/OrIvR9h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nkcong206/Android_Detection/blob/main/crawl_data/Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "He7Mwm5ljIlF"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain\n",
        "!pip install -q langchain_community\n",
        "!pip install -q langchain-ollama\n",
        "!pip install geopy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup as bp\n",
        "import time\n",
        "import csv\n",
        "import json\n",
        "from geopy.geocoders import Nominatim\n",
        "import re\n",
        "from langchain_community.chat_models import ChatOllama"
      ],
      "metadata": {
        "id": "kK3EXAqajNfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://ollama.ai/install.sh | sh"
      ],
      "metadata": {
        "id": "xpv_C9nojPId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import time\n",
        "import threading\n",
        "\n",
        "# Start the ollama server in a new process\n",
        "process = subprocess.Popen(['ollama', 'serve'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "# Function to print server output\n",
        "def print_output(process):\n",
        "    while True:\n",
        "        output = process.stdout.readline()\n",
        "        if output == b'' and process.poll() is not None:\n",
        "            break\n",
        "        if output:\n",
        "            print(output.strip().decode('utf-8'))\n",
        "        time.sleep(1)\n",
        "\n",
        "# Start a thread to print server output\n",
        "thread = threading.Thread(target=print_output, args=(process,))\n",
        "thread.start()\n",
        "\n",
        "print(\"Ollama server is running in the background\")"
      ],
      "metadata": {
        "id": "kqSTx0zMjSWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama pull llama3:latest"
      ],
      "metadata": {
        "id": "yawQKSuCjT4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOllama(model=\"llama3:latest\", temperature=0)"
      ],
      "metadata": {
        "id": "IqdgYVsBjWPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USER_AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36'\n",
        "REQUEST_HEADER = {\n",
        "    'User-Agent': USER_AGENT,\n",
        "    'Accept-language': 'en-US, en;q=0.5',\n",
        "}"
      ],
      "metadata": {
        "id": "YirzaZCUkz2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```\n",
        "DROP SCHEMA IF EXISTS places CASCADE;\n",
        "CREATE SCHEMA IF NOT EXISTS places;\n",
        "SET search_path TO places;\n",
        "\n",
        "CREATE TYPE address AS (\n",
        "    street TEXT,\n",
        "    district TEXT,\n",
        "    city TEXT\n",
        ");\n",
        "\n",
        "CREATE TYPE location AS (\n",
        "    latitude DECIMAL(9, 6),\n",
        "    longitude DECIMAL(9, 6)\n",
        ");\n",
        "\n",
        "CREATE TABLE places.hotels (\n",
        "    hotel_id SERIAL PRIMARY KEY,\n",
        "    name VARCHAR(255),\n",
        "    address address,\n",
        "    location location,\n",
        "    rating DECIMAL(2, 1),\n",
        "    description TEXT,\n",
        "    img_url JSON,\n",
        "    comments TEXT\n",
        ");\n",
        "\n",
        "CREATE TABLE places.hotel_price_range (\n",
        "    id SERIAL PRIMARY KEY,\n",
        "    hotel_id INT REFERENCES places.hotels(hotel_id) ON DELETE CASCADE,\n",
        "    room_type VARCHAR(100),\n",
        "    occupancy INT,\n",
        "    price DECIMAL(10, 2)\n",
        ");\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "NaGHpNGHlC7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_page_html(url):\n",
        "    res = requests.get(url=url, headers=REQUEST_HEADER)\n",
        "    return res.text\n",
        "\n",
        "def get_hotel_price(soup):\n",
        "    price_element = soup.find('div', attrs={'style': 'color: rgb(255, 94, 31); font-size: 20px;'})\n",
        "    if price_element:\n",
        "        true_price = price_element.text.strip().replace('VND', '').replace('.', '')\n",
        "        return float(true_price)\n",
        "    return None\n",
        "\n",
        "def get_hotel_name(soup):\n",
        "    name = soup.find('div', class_='css-901oao r-a5wbuh r-1enofrn r-b88u0q r-1cwl3u0 r-fdjqy7 r-3s2u2q')\n",
        "    return name.text.strip() if name else None\n",
        "\n",
        "def get_hotel_rating(soup):\n",
        "    rating = soup.find('div', class_='css-901oao r-jwli3a r-a5wbuh r-s67bdx r-b88u0q r-10cxs7j r-q4m81j')\n",
        "    return rating.text.strip() if rating else None\n",
        "\n",
        "def get_hotel_des(soup):\n",
        "    des = soup.find('div', attrs={'style': 'font-family:Godwit, -apple-system, BlinkMacSystemFont, Segoe UI, Roboto, Arial, sans-serif, Apple Color Emoji, Segoe UI Emoji, Segoe UI Symbol;font-size:14px;line-height:20px;max-height:80px;overflow:hidden'})\n",
        "    return des.text.strip().replace('\\n', '') if des else None\n",
        "\n",
        "def get_hotel_address(soup):\n",
        "    address = soup.find('div', class_='css-901oao css-cens5h r-13awgt0 r-a5wbuh r-1b43r93 r-majxgm r-rjixqe r-fdjqy7')\n",
        "    if address:\n",
        "        address_full = address.text.strip().replace('\\t', '')\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "            Please separate the following address into 3 parts: street, district, city:\n",
        "            {address_full}\n",
        "\n",
        "            Ensure that the \"district\" value is one of the following 12 options: Ba Đình, Cầu Giấy, Đống Đa, Hai Bà Trưng, Hoàn Kiếm, Thanh Xuân, Hoàng Mai, Long Biên, Hà Đông, Tây Hồ, Nam Từ Liêm, Bắc Từ Liêm.\n",
        "            The \"city\" value must be Hà Nội.\n",
        "\n",
        "            Provide the result in the following JSON format:\n",
        "            {{\n",
        "            \"street\": \"...\",\n",
        "            \"district\": \"...\",\n",
        "            \"city\": \"...\"\n",
        "            }}\n",
        "        \"\"\"\n",
        "        response = llm.invoke(prompt)\n",
        "        response_text = str(response.content)\n",
        "        cleaned_json_str = re.search(r'\\{.*?\\}', response_text, re.DOTALL).group(0)\n",
        "        try:\n",
        "            result_dict = json.loads(cleaned_json_str)\n",
        "            return result_dict\n",
        "        except json.JSONDecodeError:\n",
        "            return {'street': '', 'district': '', 'city': ''}\n",
        "\n",
        "def get_hotel_location(address):\n",
        "    addr = f\"{address['street']}, {address['district']}, {address['city']}\"\n",
        "    geolocator = Nominatim(user_agent=\"my_geocoder\")\n",
        "    location = geolocator.geocode(addr)\n",
        "\n",
        "    if location:\n",
        "        latitude = location.latitude\n",
        "        longitude = location.longitude\n",
        "        return {'latitude': latitude, 'longitude': longitude}\n",
        "    else:\n",
        "        return {'latitude': '', 'longitude': ''}\n",
        "\n",
        "def get_hotel_comments(soup):\n",
        "    comments = []\n",
        "    a = soup.findAll('div', class_='css-901oao css-cens5h r-cwxd7f r-a5wbuh r-1b43r93 r-majxgm r-rjixqe r-fdjqy7')\n",
        "    for comment in a:\n",
        "        comments.append(comment.text.strip())\n",
        "    return comments\n",
        "\n",
        "def insert_hotel_data(conn, info):\n",
        "    cur = conn.cursor()\n",
        "    try:\n",
        "        cur.execute(\"\"\"\n",
        "            INSERT INTO places.hotels (name, address, location, rating, description, img_url, comments)\n",
        "            VALUES (%s, ROW(%s, %s, %s), ROW(%s, %s), %s, %s, %s, %s)\n",
        "            RETURNING hotel_id;\n",
        "        \"\"\", (\n",
        "            info['name'],\n",
        "            info['address']['street'],\n",
        "            info['address']['district'],\n",
        "            info['address']['city'],\n",
        "            info['location']['latitude'],\n",
        "            info['location']['longitude'],\n",
        "            info['rating'],\n",
        "            info['description'],\n",
        "            info.get('img_url', None),\n",
        "            info['comments']\n",
        "        ))\n",
        "\n",
        "        hotel_id = cur.fetchone()[0]\n",
        "\n",
        "        if 'price' in info:\n",
        "            cur.execute(\"\"\"\n",
        "                INSERT INTO places.hotel_price_range (hotel_id, room_type, occupancy, price)\n",
        "                VALUES (%s, %s, %s, %s)\n",
        "            \"\"\", (\n",
        "                hotel_id,\n",
        "                info.get('room_type', None),\n",
        "                info.get('occupancy', None),\n",
        "                info['price']\n",
        "            ))\n",
        "\n",
        "        conn.commit()\n",
        "    except Exception as e:\n",
        "        print(f\"Error inserting data: {e}\")\n",
        "        conn.rollback()\n",
        "    finally:\n",
        "        cur.close()\n",
        "\n",
        "def extract_hotels_info(url):\n",
        "    info = {}\n",
        "    html = get_page_html(url)\n",
        "    soup = bp(html, 'lxml')\n",
        "    info['name'] = get_hotel_name(soup)\n",
        "    info['price'] = get_hotel_price(soup)\n",
        "    info['rating'] = get_hotel_rating(soup)\n",
        "    info['address'] = get_hotel_address(soup)\n",
        "    info['location'] = get_hotel_location(info['address'])\n",
        "    info['description'] = get_hotel_des(soup)\n",
        "    info['comments'] = get_hotel_comments(soup)\n",
        "    return info"
      ],
      "metadata": {
        "id": "m0xq5LhbjasJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://www.traveloka.com/vi-vn/hotel/vietnam/classy-holiday-hotel--spa-1000000430274?spec=18-08-2024.19-08-2024.1.1.HOTEL.1000000430274..2\"\n",
        "html = get_page_html(url)\n",
        "soup = bp(html, 'lxml')\n",
        "address = get_hotel_address(soup)\n",
        "print(address)\n",
        "location = get_hotel_location(address)\n",
        "print(location)"
      ],
      "metadata": {
        "id": "1QfaiH-pjgk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_page_html(url):\n",
        "    res = requests.get(url=url, headers=REQUEST_HEADER)\n",
        "    return res.text\n",
        "\n",
        "def get_restaurant_name(soup):\n",
        "    name = soup.find('h1', itemprop='name')\n",
        "    return name.text.strip() if name else None\n",
        "\n",
        "def get_restaurant_address(soup):\n",
        "    # Extract address components\n",
        "    street_address = soup.find('span', itemprop='streetAddress')\n",
        "    address_locality = soup.find('span', itemprop='addressLocality')\n",
        "    address_region = soup.find('span', itemprop='addressRegion')\n",
        "\n",
        "    address_data = {\n",
        "        'street': street_address.get_text(strip=True) if street_address else None,\n",
        "        'district': address_locality.get_text(strip=True) if address_locality else None,\n",
        "        'city': address_region.get_text(strip=True) if address_region else None\n",
        "    }\n",
        "    return address_data\n",
        "\n",
        "def get_restaurant_location(address):\n",
        "    addr = f\"{address['street']}, {address['district']}, {address['city']}\"\n",
        "    geolocator = Nominatim(user_agent=\"my_geocoder\")\n",
        "    location = geolocator.geocode(addr)\n",
        "\n",
        "    if location:\n",
        "        latitude = location.latitude\n",
        "        longitude = location.longitude\n",
        "        return {'latitude': latitude, 'longitude': longitude}\n",
        "\n",
        "def get_restaurant_rating(soup):\n",
        "    rating = soup.find('div', itemprop='ratingValue', class_='microsite-point-avg')\n",
        "    return rating.get_text(strip=True) if rating else None\n",
        "\n",
        "def get_restaurant_description(soup):\n",
        "    # Extract cuisine type\n",
        "    cuisine = soup.find('div', itemprop='servesCuisine')\n",
        "    cuisine_text = cuisine.get_text(strip=True) if cuisine else None\n",
        "\n",
        "    # Extract audience\n",
        "    audience = soup.find('div', class_='audiences')\n",
        "    audience_text = audience.get_text(strip=True).replace('&nbsp;', ' ') if audience else None\n",
        "\n",
        "    # Extract category\n",
        "    category = soup.find('div', class_='category-items')\n",
        "    category_text = category.get_text(strip=True) if category else None\n",
        "\n",
        "    # Combine all parts into a single description\n",
        "    description = {\n",
        "        'cuisine': cuisine_text,\n",
        "        'audience': audience_text,\n",
        "        'category': category_text\n",
        "    }\n",
        "    return description\n",
        "\n",
        "def get_restaurant_comments(soup):\n",
        "    comments = []\n",
        "    comment_elements = soup.findAll('div', class_='comment')\n",
        "    for comment in comment_elements:\n",
        "        comments.append(comment.text.strip())\n",
        "    return comments\n",
        "\n",
        "def extract_restaurant_info(url):\n",
        "    info = {}\n",
        "    html = get_page_html(url=url)\n",
        "    soup = bp(html, 'lxml')\n",
        "    info['name'] = get_restaurant_name(soup)\n",
        "    info['address'] = get_restaurant_address(soup)\n",
        "    info['location'] = get_restaurant_location(info['address'])\n",
        "    info['rating'] = get_restaurant_rating(soup)\n",
        "    info['description'] = get_restaurant_description(soup)\n",
        "    info['comments'] = get_restaurant_comments(soup)\n",
        "    return info"
      ],
      "metadata": {
        "id": "KaYOOiURk6UK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://www.foody.vn/ha-noi/kfc-tay-son\"\n",
        "html = get_page_html(url)\n",
        "soup = bp(html, 'lxml')\n",
        "print(get_restaurant_name(soup))\n",
        "print(get_restaurant_rating(soup))\n",
        "print(get_restaurant_description(soup))\n",
        "#print(get_restaurant_comments(soup))"
      ],
      "metadata": {
        "id": "PT_O0fahlPGF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}